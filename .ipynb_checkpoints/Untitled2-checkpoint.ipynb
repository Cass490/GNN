{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91407fb-a6e8-4339-8481-30fbda9d5d7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 331)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:331\u001b[0;36m\u001b[0m\n\u001b[0;31m    for filename in val_files:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, node_features, adj_matrix):\n",
    "         # Perform a matrix multiplication for neighbor aggregation\n",
    "         aggregated_features = torch.matmul(adj_matrix, node_features)\n",
    "         # Linear Transformation\n",
    "         node_embeddings = self.linear(aggregated_features)\n",
    "         return node_embeddings\n",
    "\n",
    "class MyGCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MyGCN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(input_dim, hidden_dim)\n",
    "        self.gcn2 = GCNLayer(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, adj_matrix, node_features):\n",
    "      # Perform forward pass with activation\n",
    "      h1 = F.relu(self.gcn1(node_features, adj_matrix))\n",
    "      h2 = self.gcn2(h1, adj_matrix)\n",
    "      return h2\n",
    "\n",
    "\n",
    "class MyHeuristic():\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "\n",
    "    def __call__(self, gnn_embeddings, raw_features):\n",
    "      #Implement your heuristic function\n",
    "       priorities = {}\n",
    "       for key, values in raw_features[\"jobs\"].items():\n",
    "           job_id = values[\"job_id\"]\n",
    "           priority = values[\"priority\"]\n",
    "           priorities[f\"job_{job_id}\"]=priority\n",
    "       action = max(priorities, key = priorities.get)\n",
    "       return action\n",
    "\n",
    "class FMSDatasetGenerator:\n",
    "    \"\"\"Generates datasets for an FMS scheduling problem.\"\"\"\n",
    "\n",
    "    def __init__(self, num_jobs, num_machines, num_ops_per_job_range, processing_time_range,\n",
    "                 failure_rate, setup_time_range, resource_capacity, load_factor,\n",
    "                 dynamic_arrival=True, fixed_routing=False):\n",
    "        \"\"\"\n",
    "        Initializes the generator.\n",
    "        Args:\n",
    "            num_jobs (int or tuple): The number of jobs, or a range for the number of jobs\n",
    "            num_machines (int): The number of machines.\n",
    "            num_ops_per_job_range (tuple): Range of operations a job can have.\n",
    "            processing_time_range (tuple): Processing time range (min, max).\n",
    "            failure_rate (float): Probability of machine failure (per simulation step).\n",
    "            setup_time_range (tuple): range for setup times (min, max).\n",
    "            resource_capacity(int): number of resources shared by machines\n",
    "            load_factor (float): Load factor for resource contention(percentage of machines that need shared resources).\n",
    "            dynamic_arrival (bool): Whether to add dynamic arrivals\n",
    "            fixed_routing (bool): whether the routing for each job is fixed\n",
    "        \"\"\"\n",
    "        self.num_jobs = num_jobs if isinstance(num_jobs, int) else random.randint(*num_jobs)\n",
    "        self.num_machines = num_machines\n",
    "        self.num_ops_per_job_range = num_ops_per_job_range\n",
    "        self.processing_time_range = processing_time_range\n",
    "        self.failure_rate = failure_rate\n",
    "        self.setup_time_range = setup_time_range\n",
    "        self.resource_capacity = resource_capacity\n",
    "        self.load_factor = load_factor\n",
    "        self.dynamic_arrival = dynamic_arrival\n",
    "        self.fixed_routing = fixed_routing\n",
    "        self.machines = self._generate_machines()\n",
    "        self.jobs = self._generate_jobs()\n",
    "        self.resources = self._generate_resources()\n",
    "\n",
    "    def _generate_resources(self):\n",
    "      resources = {\n",
    "          \"resource_capacity\": self.resource_capacity,\n",
    "          \"machines\":  random.sample(self.machines, int(len(self.machines) * self.load_factor))\n",
    "      }\n",
    "      return resources\n",
    "\n",
    "    def _generate_machines(self):\n",
    "        \"\"\"Generates machine data.\"\"\"\n",
    "        machines = []\n",
    "        for machine_id in range(self.num_machines):\n",
    "            machines.append({\"machine_id\": machine_id,\n",
    "                               \"status\": \"available\",  # initially available\n",
    "                               \"current_job\": None,\n",
    "                               \"next_available_time\": 0,\n",
    "                               \"type\": random.choice([\"general\", \"special\"])  # Example of different machine types\n",
    "                              })\n",
    "        return machines\n",
    "\n",
    "    def _generate_jobs(self):\n",
    "      \"\"\"Generates job data.\"\"\"\n",
    "      jobs = []\n",
    "      for job_id in range(self.num_jobs):\n",
    "          num_ops = random.randint(*self.num_ops_per_job_range)\n",
    "          ops = self._generate_job_ops(job_id, num_ops)\n",
    "          jobs.append({\"job_id\": job_id, \"operations\": ops,\n",
    "                       \"arrival_time\": 0 if not self.dynamic_arrival else random.randint(0,50),\n",
    "                       \"completed_operations\":0,\n",
    "                       \"priority\": random.randint(1,5),\n",
    "                       \"machine_seq\": [op[\"machine\"] for op in ops],\n",
    "                       \"current_operation\":0\n",
    "                       })\n",
    "      return jobs\n",
    "\n",
    "    def _generate_job_ops(self, job_id, num_ops):\n",
    "        \"\"\"Generates operations for a single job.\"\"\"\n",
    "        ops = []\n",
    "        available_machines = self._get_available_machines()\n",
    "        if self.fixed_routing:\n",
    "          machine_seq = random.sample(available_machines, num_ops)\n",
    "        else:\n",
    "            machine_seq = []\n",
    "\n",
    "        for op_id in range(num_ops):\n",
    "          if self.fixed_routing:\n",
    "            machine = machine_seq[op_id]\n",
    "          else:\n",
    "              machine = random.choice(available_machines)\n",
    "          proc_time = self._triangular_distribution(*self.processing_time_range)\n",
    "          setup_time = random.uniform(*self.setup_time_range) if op_id > 0 else 0.0\n",
    "          ops.append({\"job_id\": job_id, \"op_id\": op_id, \"machine\": machine,\n",
    "                          \"processing_time\": proc_time, \"setup_time\": setup_time,\n",
    "                          \"status\": \"pending\"  # initially pending\n",
    "                         })\n",
    "        return ops\n",
    "\n",
    "    def _triangular_distribution(self, min, max):\n",
    "        mode = (min + max)/2\n",
    "        u = random.uniform(0,1)\n",
    "        if u <= (mode-min)/(max-min):\n",
    "            return min + np.sqrt(u*(max-min)*(mode-min))\n",
    "        else:\n",
    "             return max-np.sqrt((1-u)*(max-min)*(max-mode))\n",
    "\n",
    "    def _get_available_machines(self):\n",
    "      available_machines = []\n",
    "      for m in self.machines:\n",
    "          available_machines.append(m[\"machine_id\"])\n",
    "      return available_machines\n",
    "\n",
    "\n",
    "    def save_dataset(self, filename, save_dir):\n",
    "        \"\"\"Saves dataset to a JSON file.\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok = True)\n",
    "        dataset = {\n",
    "            \"jobs\": self.jobs,\n",
    "            \"machines\": self.machines,\n",
    "            \"resources\": self.resources,\n",
    "        }\n",
    "\n",
    "        with open(os.path.join(save_dir,filename), 'w') as f:\n",
    "            json.dump(dataset, f, indent=4)\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset(cls, filename):\n",
    "        \"\"\"Loads dataset from a JSON file.\"\"\"\n",
    "        with open(filename, 'r') as f:\n",
    "            dataset = json.load(f)\n",
    "\n",
    "        instance = cls(num_jobs=len(dataset['jobs']),\n",
    "                      num_machines=len(dataset['machines']),\n",
    "                      num_ops_per_job_range=(3, 5),  # Dummy range\n",
    "                      processing_time_range=(2, 10),  # Dummy range\n",
    "                      failure_rate=0.1,  # Dummy rate\n",
    "                      setup_time_range=(1, 2),  # Dummy time\n",
    "                      resource_capacity=5,  # Dummy capacity\n",
    "                      load_factor=0.4  # Dummy load factor\n",
    "                      )\n",
    "        instance.jobs = dataset[\"jobs\"]\n",
    "        instance.machines = dataset[\"machines\"]\n",
    "        instance.resources = dataset[\"resources\"]\n",
    "        return instance\n",
    "\n",
    "def create_graph_and_features(dataset, current_time = 0):\n",
    "  \"\"\"\n",
    "        Creates graph data and feature vectors from current dataset status.\n",
    "        Args:\n",
    "            dataset (dict): The loaded dataset from JSON\n",
    "            current_time (int): current time of the simulation\n",
    "        Returns:\n",
    "            tuple: (graph_data (nx.Graph), heuristic_data (dict))\n",
    "        \"\"\"\n",
    "  jobs = dataset.jobs\n",
    "  machines = dataset.machines\n",
    "  graph = nx.DiGraph()\n",
    "  heuristic_data = {\"jobs\": [], \"machines\": [], \"operations\": []}\n",
    "   # 1. Node generation:\n",
    "  # Add job nodes\n",
    "  for job in jobs:\n",
    "      graph.add_node(f\"job_{job['job_id']}\", type=\"job\", **job)\n",
    "      heuristic_data[\"jobs\"].append(_extract_job_features(job,current_time))\n",
    "\n",
    "  # Add machine nodes\n",
    "  for machine in machines:\n",
    "    # Create a copy without 'type' or any other non-node property\n",
    "      machine_node_data = {k: v for k, v in machine.items() if k not in [\"type\", \"current_job\"]}\n",
    "      graph.add_node(f\"machine_{machine['machine_id']}\", type=\"machine\", **machine_node_data)\n",
    "      heuristic_data[\"machines\"].append(_extract_machine_features(machine, current_time))\n",
    "\n",
    "  # Add operation nodes\n",
    "  for job in jobs:\n",
    "      for op in job[\"operations\"]:\n",
    "          graph.add_node(f\"op_{job['job_id']}_{op['op_id']}\", type=\"operation\", **op)\n",
    "          heuristic_data[\"operations\"].append(_extract_op_features(op, job, current_time))\n",
    "\n",
    "  # 2. Edge Generation\n",
    "  #Edges for operations in a job sequence\n",
    "  for job in jobs:\n",
    "      ops = job[\"operations\"]\n",
    "      for i in range(len(ops)-1):\n",
    "          graph.add_edge(f\"op_{job['job_id']}_{ops[i]['op_id']}\",\n",
    "                      f\"op_{job['job_id']}_{ops[i+1]['op_id']}\", type=\"op_seq\")\n",
    "\n",
    "  #Edges between operations and machines\n",
    "  for job in jobs:\n",
    "      for op in job[\"operations\"]:\n",
    "         machine_node = f\"machine_{op['machine']}\"\n",
    "         graph.add_edge(f\"op_{job['job_id']}_{op['op_id']}\", machine_node, type=\"machine_link\")\n",
    "\n",
    "  #Disjunctive edges for operations in a machine\n",
    "  for m in machines:\n",
    "      ops_in_machine = []\n",
    "      for job in jobs:\n",
    "          for op in job[\"operations\"]:\n",
    "              if op[\"machine\"] == m[\"machine_id\"]:\n",
    "                  ops_in_machine.append(f\"op_{job['job_id']}_{op['op_id']}\")\n",
    "      for i in range(len(ops_in_machine)):\n",
    "          for j in range(i+1, len(ops_in_machine)):\n",
    "              graph.add_edge(ops_in_machine[i], ops_in_machine[j], type = \"disjunctive_link\")\n",
    "\n",
    "  return graph, heuristic_data\n",
    "\n",
    "\n",
    "def _extract_job_features(job, current_time):\n",
    "   \"\"\"\n",
    "       Extracts a feature vector for job.\n",
    "       Args:\n",
    "            job (dict): current job\n",
    "           current_time (int): current simulation time\n",
    "       Returns:\n",
    "            dict: features\n",
    "       \"\"\"\n",
    "   time_since_arrival = current_time-job[\"arrival_time\"]\n",
    "   remaining_operations = len(job[\"operations\"])- job[\"completed_operations\"]\n",
    "   features = {\"job_id\": job[\"job_id\"],\n",
    "               \"priority\": job[\"priority\"],\n",
    "               \"time_since_arrival\": time_since_arrival,\n",
    "               \"remaining_operations\":remaining_operations,\n",
    "               \"completed_operations\": job[\"completed_operations\"]\n",
    "               }\n",
    "   return features\n",
    "\n",
    "def _extract_machine_features(machine, current_time):\n",
    "   \"\"\"Extracts a feature vector for machine\"\"\"\n",
    "   features = { \"machine_id\": machine[\"machine_id\"],\n",
    "               \"status\": machine[\"status\"],\n",
    "                \"next_available_time\": machine[\"next_available_time\"] - current_time if machine[\"status\"]==\"busy\" else 0 ,\n",
    "              \"type\": machine[\"type\"]}\n",
    "   return features\n",
    "\n",
    "def _extract_op_features(op, job, current_time):\n",
    "   \"\"\"Extracts a feature vector for operation.\"\"\"\n",
    "   features = { \"job_id\": job[\"job_id\"],\n",
    "               \"op_id\": op[\"op_id\"],\n",
    "                \"machine\": op[\"machine\"],\n",
    "                \"processing_time\": op[\"processing_time\"],\n",
    "                \"setup_time\": op[\"setup_time\"],\n",
    "                \"status\": op[\"status\"]\n",
    "   }\n",
    "   return features\n",
    "def prepare_gnn_input(graph, feature_data):\n",
    "    \"\"\"Prepares data for your GNN.\"\"\"\n",
    "    # 1. Node Features\n",
    "    node_features = []\n",
    "    node_ids = []\n",
    "    for node_id, node_data in graph.nodes(data=True):\n",
    "       if node_data[\"type\"]==\"job\":\n",
    "           node_features.append(list(feature_data[\"jobs\"][node_id].values()))\n",
    "       elif node_data[\"type\"]==\"machine\":\n",
    "         node_features.append(list(feature_data[\"machines\"][node_id].values()))\n",
    "       elif node_data[\"type\"]==\"operation\":\n",
    "        node_features.append(list(feature_data[\"operations\"][node_id].values()))\n",
    "       node_ids.append(node_id)\n",
    "\n",
    "    node_features_tensor = torch.tensor(node_features, dtype=torch.float32)\n",
    "\n",
    "     # 2. Edge list and edge features (optional based on the GNN used)\n",
    "    edge_list = list(graph.edges())\n",
    "    edge_features = []\n",
    "    # create indices based on node_id, then create a tensor of edges\n",
    "    node_ids_map = {value: index for index, value in enumerate(node_ids)}\n",
    "    edge_index_list = [[node_ids_map[edge[0]], node_ids_map[edge[1]]] for edge in edge_list]\n",
    "    edge_index_tensor = torch.tensor(edge_index_list, dtype = torch.long).t().contiguous()\n",
    "\n",
    "    # Create adjacency matrix\n",
    "    adj_matrix = nx.to_numpy_array(graph, nodelist = node_ids)\n",
    "    adj_matrix_tensor = torch.tensor(adj_matrix, dtype=torch.float32)\n",
    "    return  node_features_tensor, adj_matrix_tensor, edge_features\n",
    "\n",
    "\n",
    "\n",
    "# --- 4. Main Loop ---\n",
    "def main_simulation(train_data_dir, val_data_dir, test_data_dir,\n",
    "             gnn_model, heuristic_algo, train_iters):\n",
    "   train_files = os.listdir(train_data_dir)\n",
    "   val_files = os.listdir(val_data_dir)\n",
    "   test_files = os.listdir(test_data_dir)\n",
    "    # --- Training Loop ---\n",
    "   for i in range(train_iters):\n",
    "     for filename in train_files:\n",
    "      loaded_generator, graph, feature_data = load_and_create_dataset(os.path.join(train_data_dir,filename), current_time=i)\n",
    "      node_features, adj_matrix, edge_features = prepare_gnn_input(graph, feature_data)\n",
    "      output = gnn_model(adj_matrix, node_features)\n",
    "      action = heuristic_algo(output, feature_data)\n",
    "      # simulate system behavior with the selected action, update system, backpropagate to update GNN parameters\n",
    "      # calculate rewards, update GNN weights based on your loss function\n",
    "      print(f\"Selected job: {action}\")\n",
    "\n",
    "    # --- Validation Loop ---\n",
    "    for filename in val_files:\n",
    "      loaded_generator, graph, feature_data = load_and_create_dataset(os.path.join(val_data_dir,filename), current_time=i)\n",
    "      node_features, adj_matrix, edge_features = prepare_gnn_input(graph, feature_data)\n",
    "      output = gnn_model(adj_matrix, node_features)\n",
    "      action = heuristic_algo(output, feature_data)\n",
    "    # simulate system behavior with the selected action, update system, calculate evaluation metrics\n",
    "\n",
    "   # --- Test Loop ---\n",
    "    for filename in test_files:\n",
    "      loaded_generator, graph, feature_data = load_and_create_dataset(os.path.join(test_data_dir,filename), current_time=i)\n",
    "      node_features, adj_matrix, edge_features = prepare_gnn_input(graph, feature_data)\n",
    "      output = gnn_model(adj_matrix, node_features)\n",
    "      action = heuristic_algo(output, feature_data)\n",
    "    # simulate system behavior with the selected action, update system, calculate evaluation metrics\n",
    "\n",
    "# ----- Generate and Save Multiple Datasets -----\n",
    "num_datasets = 10000\n",
    "train_split = 0.7\n",
    "val_split = 0.2\n",
    "test_split = 0.1\n",
    "\n",
    "train_data_dir = 'fms_train_data'\n",
    "val_data_dir = 'fms_val_data'\n",
    "test_data_dir = 'fms_test_data'\n",
    "\n",
    "os.makedirs(train_data_dir, exist_ok = True)\n",
    "os.makedirs(val_data_dir, exist_ok = True)\n",
    "os.makedirs(test_data_dir, exist_ok = True)\n",
    "\n",
    "for i in range(num_datasets):\n",
    "    generator = FMSDatasetGenerator(\n",
    "        num_jobs=(20, 100),  # Variable number of jobs\n",
    "        num_machines=10,\n",
    "        num_ops_per_job_range=(3, 8),\n",
    "        processing_time_range=(2, 20),\n",
    "        failure_rate=0.05,\n",
    "        setup_time_range=(0, 3),\n",
    "        resource_capacity = 6,\n",
    "        load_factor = 0.6,\n",
    "        dynamic_arrival=True,\n",
    "        fixed_routing = False\n",
    "    )\n",
    "    if i < num_datasets * train_split:\n",
    "        save_dir = train_data_dir\n",
    "    elif i < num_datasets * (train_split + val_split):\n",
    "        save_dir = val_data_dir\n",
    "    else:\n",
    "         save_dir = test_data_dir\n",
    "\n",
    "    filename = f\"fms_dataset_{i}.json\"\n",
    "    generator.save_dataset(filename, save_dir)\n",
    "    print(f\"Dataset {i+1}/{num_datasets} generated and saved to {filename}\")\n",
    "\n",
    "print(\"All datasets generated.\")\n",
    "\n",
    "# ----- Load and check one example -----\n",
    "loaded_generator = FMSDatasetGenerator.load_dataset(os.path.join(train_data_dir, \"fms_dataset_0.json\"))\n",
    "loaded_graph, loaded_heuristic = create_graph_and_features(loaded_generator,0)\n",
    "print(f\"Number of nodes: {len(loaded_graph.nodes)}\")\n",
    "print(f\"Number of edges: {len(loaded_graph.edges)}\")\n",
    "print(f\"Number of jobs: {len(loaded_generator.jobs)}\")\n",
    "print(f\"Number of machines: {len(loaded_generator.machines)}\")\n",
    "print(f\"Number of resources: {loaded_generator.resources}\")\n",
    "\n",
    "if  loaded_heuristic['jobs']:\n",
    "   print(f\"Example of job feature list: {loaded_heuristic['jobs'][0]}\")\n",
    "else:\n",
    "    print(\"Job feature list is empty\")\n",
    "if loaded_heuristic['machines']:\n",
    "   print(f\"Example of machine feature list: {loaded_heuristic['machines'][0]}\")\n",
    "else:\n",
    "    print(\"Machine feature list is empty\")\n",
    "if loaded_heuristic['operations']:\n",
    "   print(f\"Example of operation feature list: {loaded_heuristic['operations'][0]}\")\n",
    "else:\n",
    "    print(\"Operation feature list is empty\")\n",
    "\n",
    "# --- Setup and Run ---\n",
    "input_dim = 9 #number of node features\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "\n",
    "my_gnn_model = MyGCN(input_dim, hidden_dim, output_dim) # Dummy Implementation\n",
    "my_heuristic = MyHeuristic(params = None) # Dummy Implementation\n",
    "main_simulation(train_data_dir,val_data_dir, test_data_dir, my_gnn_model, my_heuristic, train_iters = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f01fe-1645-4ab6-86ff-74c7646cd578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
